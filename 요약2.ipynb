{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da470f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T02:47:08.657756Z",
     "start_time": "2021-10-22T02:47:08.654652Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "kddcup = os.path.join(os.getcwd(),'kddcup.data_10_percent.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab426483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T02:49:16.534048Z",
     "start_time": "2021-10-22T02:49:07.904933Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark \n",
    "\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder.master(\"local\").appName(\"myApp\").config(conf=myConf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc84be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T02:49:49.797961Z",
     "start_time": "2021-10-22T02:49:48.869535Z"
    }
   },
   "outputs": [],
   "source": [
    "rdd_data = spark.sparkContext.textFile(kddcup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f55ea7a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T02:50:52.240870Z",
     "start_time": "2021-10-22T02:50:52.161024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bda11108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T02:52:25.285040Z",
     "start_time": "2021-10-22T02:52:25.196654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11635161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T02:58:03.220958Z",
     "start_time": "2021-10-22T02:58:03.214683Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "temp_data = rdd_data.map(lambda x : x.split(','))\n",
    "temp_data = temp_data.map(lambda p: Row(\n",
    "                        duration=int(p[0]), \n",
    "                        protocol=p[1],\n",
    "                        service=p[2],\n",
    "                        flag=p[3],\n",
    "                        src_bytes=int(p[4]),\n",
    "                        dst_bytes=int(p[5]),\n",
    "                        attack=p[41]\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66516409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T02:58:04.709006Z",
     "start_time": "2021-10-22T02:58:04.514257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+----+---------+---------+-------+\n",
      "|duration|protocol|service|flag|src_bytes|dst_bytes| attack|\n",
      "+--------+--------+-------+----+---------+---------+-------+\n",
      "|       0|     tcp|   http|  SF|      181|     5450|normal.|\n",
      "|       0|     tcp|   http|  SF|      239|      486|normal.|\n",
      "|       0|     tcp|   http|  SF|      235|     1337|normal.|\n",
      "|       0|     tcp|   http|  SF|      219|     1337|normal.|\n",
      "|       0|     tcp|   http|  SF|      217|     2032|normal.|\n",
      "|       0|     tcp|   http|  SF|      217|     2032|normal.|\n",
      "|       0|     tcp|   http|  SF|      212|     1940|normal.|\n",
      "|       0|     tcp|   http|  SF|      159|     4087|normal.|\n",
      "|       0|     tcp|   http|  SF|      210|      151|normal.|\n",
      "|       0|     tcp|   http|  SF|      212|      786|normal.|\n",
      "|       0|     tcp|   http|  SF|      210|      624|normal.|\n",
      "|       0|     tcp|   http|  SF|      177|     1985|normal.|\n",
      "|       0|     tcp|   http|  SF|      222|      773|normal.|\n",
      "|       0|     tcp|   http|  SF|      256|     1169|normal.|\n",
      "|       0|     tcp|   http|  SF|      241|      259|normal.|\n",
      "|       0|     tcp|   http|  SF|      260|     1837|normal.|\n",
      "|       0|     tcp|   http|  SF|      241|      261|normal.|\n",
      "|       0|     tcp|   http|  SF|      257|      818|normal.|\n",
      "|       0|     tcp|   http|  SF|      233|      255|normal.|\n",
      "|       0|     tcp|   http|  SF|      233|      504|normal.|\n",
      "+--------+--------+-------+----+---------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data = spark.createDataFrame(temp_data)\n",
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7e6fbc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T02:59:08.499022Z",
     "start_time": "2021-10-22T02:59:02.403540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|          attack| count|\n",
      "+----------------+------+\n",
      "|    warezmaster.|    20|\n",
      "|          smurf.|280790|\n",
      "|            pod.|   264|\n",
      "|           imap.|    12|\n",
      "|           nmap.|   231|\n",
      "|   guess_passwd.|    53|\n",
      "|        ipsweep.|  1247|\n",
      "|      portsweep.|  1040|\n",
      "|          satan.|  1589|\n",
      "|           land.|    21|\n",
      "|     loadmodule.|     9|\n",
      "|      ftp_write.|     8|\n",
      "|buffer_overflow.|    30|\n",
      "|        rootkit.|    10|\n",
      "|    warezclient.|  1020|\n",
      "|       teardrop.|   979|\n",
      "|           perl.|     3|\n",
      "|            phf.|     4|\n",
      "|       multihop.|     7|\n",
      "|        neptune.|107201|\n",
      "+----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.groupBy('attack').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "434955a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T03:01:01.819949Z",
     "start_time": "2021-10-22T03:00:57.381892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|          attack|       avg(duration)|\n",
      "+----------------+--------------------+\n",
      "|    warezmaster.|               15.05|\n",
      "|          smurf.|                 0.0|\n",
      "|            pod.|                 0.0|\n",
      "|           imap.|                 6.0|\n",
      "|           nmap.|                 0.0|\n",
      "|   guess_passwd.|  2.7169811320754715|\n",
      "|        ipsweep.|0.034482758620689655|\n",
      "|      portsweep.|  1915.2990384615384|\n",
      "|          satan.|0.040276903713027064|\n",
      "|           land.|                 0.0|\n",
      "|     loadmodule.|   36.22222222222222|\n",
      "|      ftp_write.|              32.375|\n",
      "|buffer_overflow.|                91.7|\n",
      "|        rootkit.|               100.8|\n",
      "|    warezclient.|   615.2578431372549|\n",
      "|       teardrop.|                 0.0|\n",
      "|           perl.|  41.333333333333336|\n",
      "|            phf.|                 4.5|\n",
      "|       multihop.|               184.0|\n",
      "|        neptune.|                 0.0|\n",
      "+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.groupBy('attack').mean('duration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "859b997e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T03:09:17.231202Z",
     "start_time": "2021-10-22T03:07:53.380878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------------------+------------------+\n",
      "|          attack|              icmp|               tcp|               udp|\n",
      "+----------------+------------------+------------------+------------------+\n",
      "|    warezmaster.|              null|              49.3|              null|\n",
      "|          smurf.| 935.7722995833185|              null|              null|\n",
      "|            pod.|1462.6515151515152|              null|              null|\n",
      "|           nmap.|               8.0|               0.0|            189.88|\n",
      "|           imap.|              null| 347.5833333333333|              null|\n",
      "|   guess_passwd.|              null|125.33962264150944|              null|\n",
      "|        ipsweep.|10.905464006938422|               0.0|              null|\n",
      "|      portsweep.|               8.0| 667349.1106833494|              null|\n",
      "|          satan.|25.666666666666668| 1.323446327683616|1.0235294117647058|\n",
      "|           land.|              null|               0.0|              null|\n",
      "|     loadmodule.|              null|151.88888888888889|              null|\n",
      "|      ftp_write.|              null|            220.75|              null|\n",
      "|buffer_overflow.|              null|1400.4333333333334|              null|\n",
      "|        rootkit.|              null| 415.2857142857143|13.333333333333334|\n",
      "|    warezclient.|              null|  300219.562745098|              null|\n",
      "|       teardrop.|              null|              null|              28.0|\n",
      "|           perl.|              null| 265.6666666666667|              null|\n",
      "|            phf.|              null|              51.0|              null|\n",
      "|       multihop.|              null|435.14285714285717|              null|\n",
      "|        neptune.|              null|               0.0|              null|\n",
      "+----------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_data.groupBy('attack').pivot('protocol').agg(F.mean('src_bytes')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9be13a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T03:10:08.621114Z",
     "start_time": "2021-10-22T03:09:58.832097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------------------+------------------+\n",
      "|          attack|              icmp|               tcp|               udp|\n",
      "+----------------+------------------+------------------+------------------+\n",
      "|    warezmaster.|              null|              49.3|              null|\n",
      "|          smurf.| 935.7722995833185|              null|              null|\n",
      "|            pod.|1462.6515151515152|              null|              null|\n",
      "|           nmap.|               8.0|               0.0|            189.88|\n",
      "|           imap.|              null| 347.5833333333333|              null|\n",
      "|   guess_passwd.|              null|125.33962264150944|              null|\n",
      "|        ipsweep.|10.905464006938422|               0.0|              null|\n",
      "|      portsweep.|               8.0| 667349.1106833494|              null|\n",
      "|          satan.|25.666666666666668| 1.323446327683616|1.0235294117647058|\n",
      "|           land.|              null|               0.0|              null|\n",
      "|     loadmodule.|              null|151.88888888888889|              null|\n",
      "|      ftp_write.|              null|            220.75|              null|\n",
      "|buffer_overflow.|              null|1400.4333333333334|              null|\n",
      "|        rootkit.|              null| 415.2857142857143|13.333333333333334|\n",
      "|    warezclient.|              null|  300219.562745098|              null|\n",
      "|       teardrop.|              null|              null|              28.0|\n",
      "|           perl.|              null| 265.6666666666667|              null|\n",
      "|            phf.|              null|              51.0|              null|\n",
      "|       multihop.|              null|435.14285714285717|              null|\n",
      "|        neptune.|              null|               0.0|              null|\n",
      "+----------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.groupBy('attack').pivot('protocol').mean('src_bytes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90242d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de2841ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T03:56:29.606939Z",
     "start_time": "2021-10-22T03:56:29.601195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data/ds_bigdata_wiki.txt MapPartitionsRDD[134] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0223588c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T03:56:20.049849Z",
     "start_time": "2021-10-22T03:56:19.980712Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki_data = spark.sparkContext.textFile(os.path.join('data','ds_bigdata_wiki.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc00ebae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T04:00:46.456553Z",
     "start_time": "2021-10-22T04:00:46.322510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21, '데이터'),\n",
       " (18, '데이터를'),\n",
       " (15, '및'),\n",
       " (14, '빅'),\n",
       " (12, '등'),\n",
       " (9, '있다.'),\n",
       " (8, '수'),\n",
       " (8, '데이터의'),\n",
       " (7, '미국'),\n",
       " (7, '통해'),\n",
       " (6, '유권자'),\n",
       " (6, '선거'),\n",
       " (6, '대한'),\n",
       " (6, '빅데이터'),\n",
       " (5, '활용한')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data.flatMap(lambda x : x.split()).map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y).map(lambda x : (x[1],x[0])).sortByKey(False).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a781762a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T04:05:14.433237Z",
     "start_time": "2021-10-22T04:05:14.322573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21, '데이터'),\n",
       " (18, '데이터를'),\n",
       " (15, '및'),\n",
       " (14, '빅'),\n",
       " (12, '등'),\n",
       " (9, '있다.'),\n",
       " (8, '수'),\n",
       " (8, '데이터의'),\n",
       " (7, '미국'),\n",
       " (7, '통해'),\n",
       " (6, '유권자'),\n",
       " (6, '선거'),\n",
       " (6, '대한'),\n",
       " (6, '빅데이터'),\n",
       " (5, '활용한')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data.flatMap(lambda x : x.split()).map(lambda x: (x,1)).groupByKey().mapValues(sum).map(lambda x: (x[1],x[0])).sortByKey(False).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f920f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd2182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78765be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T04:16:30.833344Z",
     "start_time": "2021-10-22T04:16:30.825473Z"
    }
   },
   "outputs": [],
   "source": [
    "_data = [\"'김하나','English',100\",\n",
    "         \"'김하나','Math',80\",\n",
    "         \"'임하나','English',70\",\n",
    "         \"'임하나','Math',100\",\n",
    "        \"'김갑돌','English',82.3\",\n",
    "         \"'김갑돌','Math',98.5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78dc8137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T04:26:25.798079Z",
     "start_time": "2021-10-22T04:26:25.647641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'김하나'\", 180.0), (\"'임하나'\", 170.0), (\"'김갑돌'\", 180.8)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data = spark.sparkContext.parallelize(_data)\n",
    "rdd_data.map(lambda x: x.split(',')).map(lambda x : (x[0],float(x[2]))).reduceByKey(lambda x,y : x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0831f9a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T04:26:58.135323Z",
     "start_time": "2021-10-22T04:26:58.052315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'English'\", 252.3), (\"'Math'\", 278.5)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data.map(lambda x: x.split(',')).map(lambda x : (x[1],float(x[2]))).reduceByKey(lambda x,y : x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dba0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c469f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f679b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07316bab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T04:51:42.819870Z",
     "start_time": "2021-10-22T04:51:42.713039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'김하나'\", (180.0, 2)), (\"'임하나'\", (170.0, 2)), (\"'김갑돌'\", (180.8, 2))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data.map(lambda x: x.split(',')).map(lambda x: (x[0], float(x[2]))).combineByKey(lambda value: (value,1),\n",
    "                     lambda x,value: (x[0]+value, x[1]+1),                      \n",
    "                     lambda x,y: (x[0]+y[0], x[1]+y[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fac9c82a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T04:53:05.462895Z",
     "start_time": "2021-10-22T04:53:05.395242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'임하나' 85.0\n",
      "'김하나' 90.0\n",
      "'김갑돌' 90.4\n"
     ]
    }
   ],
   "source": [
    "avg = rdd_data.map(lambda x: x.split(',')).map(lambda x: (x[0], float(x[2]))).combineByKey(lambda value: (value,1),\n",
    "                     lambda x,value: (x[0]+value, x[1]+1),                      \n",
    "                     lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    "\n",
    "avg2 = avg.map(lambda x: (x[0],x[1][0]/x[1][1]))\n",
    "\n",
    "for i, j in sorted(avg2.collect(),reverse=True):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfec6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b229c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6a622034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T05:30:33.360012Z",
     "start_time": "2021-10-22T05:30:27.474019Z"
    }
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://health.data.ny.gov/api/views/jxy9-yhdk/rows.json?accessType=DOWNLOAD')\n",
    "\n",
    "wc = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "40401ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T05:34:48.574582Z",
     "start_time": "2021-10-22T05:34:48.569868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': -1,\n",
       " 'name': 'id',\n",
       " 'dataTypeName': 'meta_data',\n",
       " 'fieldName': ':id',\n",
       " 'position': 0,\n",
       " 'renderTypeName': 'meta_data',\n",
       " 'format': {},\n",
       " 'flags': ['hidden']}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc['meta']['view']['columns'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd8d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865e008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c24a20fd",
   "metadata": {},
   "source": [
    "# RDD 읽는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.parallelize(myList)\n",
    "spark.sparkContext.textFile(os.path.join(\"data\",\"ds_spark_wiki.txt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53942a31",
   "metadata": {},
   "source": [
    "# DF 읽는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.text(os.path.join(\"data\", \"ds_spark_wiki.txt\"))\n",
    "\n",
    "popDf = spark\\\n",
    "            .read.option(\"charset\", \"euc-kr\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .csv(os.path.join(\"data\",\"경기도 의정부시_인구현황_20200904.csv\"))\n",
    "\n",
    "df = spark\\\n",
    "        .read\\\n",
    "        .format('com.databricks.spark.csv')\\\n",
    "        .options(header='true', inferschema='true', delimiter=',')\\\n",
    "        .load(os.path.join('data','ds_spark.csv'))\n",
    "\n",
    "df = spark\\\n",
    "        .read.options(header='true', inferschema='true', delimiter=',')\\\n",
    "        .csv(os.path.join('data', 'ds_spark.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27d895",
   "metadata": {},
   "source": [
    "# RDD to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fe1e4c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T09:15:11.523241Z",
     "start_time": "2021-10-22T09:15:11.428003Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myRdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d3cfd3afdf8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrddDf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyRdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# row to df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_myRdd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyRdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'myRdd' is not defined"
     ]
    }
   ],
   "source": [
    "rddDf=spark.createDataFrame(myRdd)\n",
    "\n",
    "# row to df\n",
    "from pyspark.sql import Row\n",
    "_myRdd=myRdd.map(lambda x:Row(year=int(x[0]), name=x[1], height=int(x[2])))\n",
    "_myDf=spark.createDataFrame(_myRdd)\n",
    "\n",
    "\n",
    "\n",
    "#structType\n",
    "from pyspark.sql.types import *\n",
    "myRdd=spark.sparkContext.parallelize([(1, 'kim', 50.0), (2, 'lee', 60.0), (3, 'park', 70.0)])\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"height\", DoubleType(), True)\n",
    "])\n",
    "_myDf = spark.createDataFrame(myRdd, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58678b67",
   "metadata": {},
   "source": [
    "# json to spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1863f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "jfile= os.path.join('src','ds_twitter_seoul_3.json')\n",
    "tweetDf= spark.read.json(jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url json spark_df\n",
    "\n",
    "r=requests.get(\"https://raw.githubusercontent.com/jokecamp/FootballData/master/World%20Cups/all-world-cup-players.json\")\n",
    "wc=r.json()\n",
    "_wcDf=spark.createDataFrame(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93eeb9c",
   "metadata": {},
   "source": [
    "# csv 읽는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5aaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글깨짐\n",
    "spark.sparkContext.textFile(os.path.join(\"data\",\"ds_spark_2cols.csv\"))\n",
    "\n",
    "# 한글안깨짐\n",
    "popRddBin = spark.sparkContext.binaryFiles(os.path.join(\"../data\",\"경기도 의정부시_인구현황_20210910.csv\"))\n",
    "_my = popRddBin.map(lambda x :x[1].decode('euc-kr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad89733",
   "metadata": {},
   "source": [
    "# filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86315306",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['is','am','are','the','for','a', 'an', 'at']\n",
    "myRdd_stop = myRdd2.flatMap(lambda x:x.split())\\\n",
    "                    .filter(lambda x: x not in stopwords)\n",
    "\n",
    "for words in myRdd_stop.collect():\n",
    "    print (words, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e033b76",
   "metadata": {},
   "source": [
    "# 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt 읽어서 불용어 및 단어빈도\n",
    "import os\n",
    "\n",
    "f=open(os.path.join(\"data\", \"ds_bigdata_wiki.txt\"))\n",
    "\n",
    "stopwords = set(['및','이를','등','이','이런','그와','또는','두', '이와', '전', '간'])\n",
    "d = dict()\n",
    "for sent in f.readlines():\n",
    "    _words = sent.split()  # split into words\n",
    "    for word in _words:\n",
    "        if word not in stopwords: # remove stopwords\n",
    "            if word not in d:\n",
    "                d[word]=1\n",
    "            else:\n",
    "                d[word]=d[word]+1\n",
    "# sorting\n",
    "dSorted = {k: v for k, v in sorted(d.items(), key=lambda x: x[1], reverse=True)}\n",
    "\n",
    "#빈도 5 이상\n",
    "d1 = dict()\n",
    "for key, value in dSorted.items():\n",
    "    if value>5:\n",
    "        d1[key]=value\n",
    "        print (f\"{key}\\t{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "99b4d034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T09:03:33.377300Z",
     "start_time": "2021-10-22T09:03:33.338625Z"
    }
   },
   "outputs": [],
   "source": [
    "# rdd 불용어 + sorting\n",
    "\n",
    "stopwords = set(['및','이를','등','이','이런','그와','또는','두', '이와', '전', '간'])\n",
    "\n",
    "wc3=myRdd3\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .filter(lambda x: x.lower() not in stopwords)\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .reduceByKey(lambda x,y:x+y)\\\n",
    "    .map(lambda x:(x[1],x[0]))\\\n",
    "    .sortByKey(False)\\\n",
    "    .take(15)\n",
    "\n",
    "print (type(wc3))\n",
    "for i in wc3:\n",
    "    print (i[0],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백 + , + .제거\n",
    "\n",
    "wc = spark.sparkContext.textFile(os.path.join(\"data\",\"ds_spark_wiki.txt\"))\\\n",
    "    .flatMap(lambda x: x.split())\\\n",
    "    .map(lambda x: (x.lower().rstrip().lstrip().rstrip(',').rstrip('.'), 1))\n",
    "\n",
    "wcReduceByKey = wc.reduceByKey(lambda x,y:x+y)\n",
    "wcReduceByKey.sortByKey().take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b4b84",
   "metadata": {},
   "source": [
    "# datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923788dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DateType\n",
    "toDate = udf(lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
    "\n",
    "_wcDfCasted=wcDf.withColumn('date2', to_date(wcDf['DateOfBirth'], 'yyyy-MM-dd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca5325",
   "metadata": {},
   "source": [
    "# udf 조건"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "height_udf = udf(lambda height: \"taller\" if height >=175 else \"shorter\", StringType())\n",
    "heightDf=myDf.withColumn(\"height>175\", height_udf(myDf.heightD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff05df",
   "metadata": {},
   "source": [
    "# columnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d36656",
   "metadata": {},
   "outputs": [],
   "source": [
    "tDf=tDf.withColumnRenamed('id','ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a4030",
   "metadata": {},
   "source": [
    "# F함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37538eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "myDf.agg(F.min(myDf.heightD),F.max(myDf.heightD),F.avg(myDf.heightD),F.sum(myDf.heightD)).show()\n",
    "tDf.agg(F.min(\"height\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
