{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406ef0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:48:04.006059Z",
     "start_time": "2021-09-22T13:47:59.962557Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder.master('local').appName('myApp').config(conf=myConf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9cb2b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:49:50.341353Z",
     "start_time": "2021-09-22T13:49:50.230708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['행정기관,인구수(계),인구수(남),인구수(여),구성비(계),구성비(남),구성비(여),성비,세대수,세대당인구,관리기관명,관리부서명,부서전화번호,데이터기준일자\\r\\n의정부1동,32292,16538,15754,6.97,3.57,3.4,104.98,19998,1.61,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n의정부2동,31380,15608,15772,6.77,3.37,3.4,98.96,16410,1.91,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n호원1동,36124,17595,18529,7.8,3.8,4,94.96,15653,2.31,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n호원2동,34957,16923,18034,7.54,3.65,3.89,93.84,13683,2.55,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n장암동,20314,9714,10600,4.38,2.1,2.29,91.64,8604,2.36,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n신곡1동,43159,21205,21954,9.31,4.58,4.74,96.59,17990,2.4,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n신곡2동,47852,23232,24620,10.33,5.01,5.31,94.36,19218,2.49,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n송산1동,42817,21276,21541,9.24,4.59,4.65,98.77,18811,2.28,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n송산2동,33565,16601,16964,7.24,3.58,3.66,97.86,13216,2.54,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n송산3동,46892,22772,24120,10.12,4.91,5.21,94.41,17926,2.62,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n자금동,27087,13270,13817,5.85,2.86,2.98,96.04,11868,2.28,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n가능동,25990,12974,13016,5.61,2.8,2.81,99.68,12492,2.08,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n흥선동,19176,9769,9407,4.14,2.11,2.03,103.85,9380,2.04,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n녹양동,21768,10872,10896,4.7,2.35,2.35,99.78,9556,2.28,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "myDf = spark.sparkContext.binaryFiles(os.path.join('../data','경기도 의정부시_인구현황_20210910.csv'))\n",
    "\n",
    "_my = myDf.map(lambda x: x[1].decode('euc-kr'))\n",
    "\n",
    "_my.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b6a2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:49:52.329689Z",
     "start_time": "2021-09-22T13:49:52.229110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'행정기관,인구수(계),인구수(남),인구수(여),구성비(계),구성비(남),구성비(여),성비,세대수,세대당인구,관리기관명,관리부서명,부서전화번호,데이터기준일자'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popList = _my.map(lambda x: x.split()).take(3) #white space\n",
    "popList[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba283fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:51:14.538738Z",
     "start_time": "2021-09-22T13:51:11.037794Z"
    }
   },
   "outputs": [],
   "source": [
    "popDf = spark.read.option('charset','euc-kr').option('header','true').csv(os.path.join('../data','경기도 의정부시_인구현황_20210910.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc45fe00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:56:21.429765Z",
     "start_time": "2021-09-22T13:56:21.274910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "| 행정기관|인구수(계)|인구수(남)|인구수(여)|구성비(계)|구성비(남)|구성비(여)|  성비|세대수|세대당인구|관리기관명|관리부서명|부서전화번호|데이터기준일자|\n",
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "|의정부1동|     32292|     16538|     15754|      6.97|      3.57|       3.4|104.98| 19998|      1.61|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|의정부2동|     31380|     15608|     15772|      6.77|      3.37|       3.4| 98.96| 16410|      1.91|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|  호원1동|     36124|     17595|     18529|       7.8|       3.8|         4| 94.96| 15653|      2.31|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|  호원2동|     34957|     16923|     18034|      7.54|      3.65|      3.89| 93.84| 13683|      2.55|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|   장암동|     20314|      9714|     10600|      4.38|       2.1|      2.29| 91.64|  8604|      2.36|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79965ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac05d8a1",
   "metadata": {},
   "source": [
    "# ds3_spark_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "448eb389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:17:56.645386Z",
     "start_time": "2021-09-22T14:17:56.599050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[28] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "nRdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "squared = nRdd.map(lambda x: x * x)\n",
    "print (squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52786781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:18:09.157297Z",
     "start_time": "2021-09-22T14:18:09.029918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "print (squared.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dbbac0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:19:38.977662Z",
     "start_time": "2021-09-22T14:19:38.970880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../data/ds_spark_2cols.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../data/ds_spark_2cols.csv\n",
    "35, 2\n",
    "40, 27\n",
    "12, 38\n",
    "15, 31\n",
    "21, 1\n",
    "14, 19\n",
    "46, 1\n",
    "10, 34\n",
    "28, 3\n",
    "48, 1\n",
    "16, 2\n",
    "30, 3\n",
    "32, 2\n",
    "48, 1\n",
    "31, 2\n",
    "22, 1\n",
    "12, 3\n",
    "39, 29\n",
    "19, 37\n",
    "25, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "652fc685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:25:33.882459Z",
     "start_time": "2021-09-22T14:25:33.877170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../data/ds_spark_wiki.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../data/ds_spark_wiki.txt\n",
    "Wikipedia\n",
    "Apache Spark is an open source cluster computing framework.\n",
    "아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다.\n",
    "Apache Spark Apache Spark Apache Spark Apache Spark\n",
    "아파치 스파크 아파치 스파크 아파치 스파크 아파치 스파크\n",
    "Originally developed at the University of California, Berkeley's AMPLab,\n",
    "the Spark codebase was later donated to the Apache Software Foundation,\n",
    "which has maintained it since.\n",
    "Spark provides an interface for programming entire clusters with\n",
    "implicit data parallelism and fault-tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b8e6ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:20:15.672559Z",
     "start_time": "2021-09-22T14:20:15.617849Z"
    }
   },
   "outputs": [],
   "source": [
    "myRdd4 = spark.sparkContext.textFile(os.path.join('../data','ds_spark_2cols.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bea2f1f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:20:16.870539Z",
     "start_time": "2021-09-22T14:20:16.768456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['35, 2', '40, 27', '12, 38', '15, 31', '21, 1']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd4.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45027832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:21:38.150833Z",
     "start_time": "2021-09-22T14:21:38.101121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['35', ' 2'], ['40', ' 27'], ['12', ' 38'], ['15', ' 31'], ['21', ' 1']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd5 = myRdd4.map(lambda line: line.split(','))\n",
    "myRdd5.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8091ad17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:23:33.737328Z",
     "start_time": "2021-09-22T14:23:33.683385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 2], [40, 27], [12, 38], [15, 31], [21, 1]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd6 = myRdd5.map(lambda x: [int(i) for i in x])\n",
    "myRdd6.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f29201c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:26:24.558987Z",
     "start_time": "2021-09-22T14:26:24.517426Z"
    }
   },
   "outputs": [],
   "source": [
    "myRdd2=spark.sparkContext\\\n",
    "    .textFile(os.path.join(\"../data\",\"ds_spark_wiki.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40dc1834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:26:25.491423Z",
     "start_time": "2021-09-22T14:26:25.485090Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = myRdd2.map(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b758192b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:26:26.536626Z",
     "start_time": "2021-09-22T14:26:26.463299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2d74961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:26:40.951738Z",
     "start_time": "2021-09-22T14:26:40.895480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mySplit(x):\n",
    "    return x.split()\n",
    "sentences2=myRdd2.map(mySplit)\n",
    "sentences2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b9626c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:27:03.647747Z",
     "start_time": "2021-09-22T14:27:03.596194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Wikipedia'],\n",
       " ['Apache',\n",
       "  'Spark',\n",
       "  'is',\n",
       "  'an',\n",
       "  'open',\n",
       "  'source',\n",
       "  'cluster',\n",
       "  'computing',\n",
       "  'framework.'],\n",
       " ['아파치', '스파크는', '오픈', '소스', '클러스터', '컴퓨팅', '프레임워크이다.']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "090f8103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:27:31.797730Z",
     "start_time": "2021-09-22T14:27:31.721430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia \n",
      "-----\n",
      "Apache Spark is an open source cluster computing framework. \n",
      "-----\n",
      "아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다. \n",
      "-----\n",
      "Apache Spark Apache Spark Apache Spark Apache Spark \n",
      "-----\n",
      "아파치 스파크 아파치 스파크 아파치 스파크 아파치 스파크 \n",
      "-----\n",
      "Originally developed at the University of California, Berkeley's AMPLab, \n",
      "-----\n",
      "the Spark codebase was later donated to the Apache Software Foundation, \n",
      "-----\n",
      "which has maintained it since. \n",
      "-----\n",
      "Spark provides an interface for programming entire clusters with \n",
      "-----\n",
      "implicit data parallelism and fault-tolerance. \n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for line in sentences.collect():\n",
    "    for word in line:\n",
    "        print (word, end=\" \")\n",
    "    print (\"\\n-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0409d9e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:31:28.800096Z",
     "start_time": "2021-09-22T14:31:28.744878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 59, 32, 51, 31, 72, 71, 30, 64, 46]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd2.map(lambda s:len(s)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b468bd59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:32:10.287222Z",
     "start_time": "2021-09-22T14:32:10.280849Z"
    }
   },
   "outputs": [],
   "source": [
    "myList=[\"this is\",\"a line\"]\n",
    "_rdd=spark.sparkContext.parallelize(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f2ea3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:32:24.962747Z",
     "start_time": "2021-09-22T14:32:24.927635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is'], ['a', 'line']]\n"
     ]
    }
   ],
   "source": [
    "wordsRdd=_rdd.map(lambda x:x.split())\n",
    "print (wordsRdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f039d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:32:32.142155Z",
     "start_time": "2021-09-22T14:32:32.110258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is', 'AA line']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repRdd=_rdd.map(lambda x:x.replace(\"a\",\"AA\"))\n",
    "repRdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7a34fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:33:09.918821Z",
     "start_time": "2021-09-22T14:33:09.878025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THIS', 'A']\n"
     ]
    }
   ],
   "source": [
    "upperRDD =wordsRdd.map(lambda x: x[0].upper())\n",
    "print (upperRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74549e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:33:31.697362Z",
     "start_time": "2021-09-22T14:33:31.657782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['THIS', 'IS'], ['A', 'LINE']]\n"
     ]
    }
   ],
   "source": [
    "upper2RDD =wordsRdd.map(lambda x: [i.upper() for i in x])\n",
    "print (upper2RDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51114025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:33:59.232741Z",
     "start_time": "2021-09-22T14:33:59.191378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd100 = spark.sparkContext.parallelize(range(1,101))\n",
    "myRdd100.reduce(lambda subtotal, x: subtotal + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cc10311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:35:21.692323Z",
     "start_time": "2021-09-22T14:35:21.625564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many lines having 'Spark':  4\n"
     ]
    }
   ],
   "source": [
    "myRdd_spark=myRdd2.filter(lambda line: \"Spark\" in line)\n",
    "print (\"How many lines having 'Spark': \",myRdd_spark.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0607a779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:36:04.835007Z",
     "start_time": "2021-09-22T14:36:04.801516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다.\n"
     ]
    }
   ],
   "source": [
    "myRdd_unicode = myRdd2.filter(lambda line: u\"스파크\" in line)\n",
    "print (myRdd_unicode.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3efb77d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:36:31.308402Z",
     "start_time": "2021-09-22T14:36:31.304342Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = ['is','am','are','the','for','a', 'an', 'at']\n",
    "myRdd_stop = myRdd2.flatMap(lambda x:x.split())\\\n",
    "                    .filter(lambda x: x not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dc5fca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:36:40.623447Z",
     "start_time": "2021-09-22T14:36:40.573360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia Apache Spark open source cluster computing framework. 아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다. Apache Spark Apache Spark Apache Spark Apache Spark 아파치 스파크 아파치 스파크 아파치 스파크 아파치 스파크 Originally developed University of California, Berkeley's AMPLab, Spark codebase was later donated to Apache Software Foundation, which has maintained it since. Spark provides interface programming entire clusters with implicit data parallelism and fault-tolerance. "
     ]
    }
   ],
   "source": [
    "for words in myRdd_stop.collect():\n",
    "    print (words, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aed15ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:37:59.669558Z",
     "start_time": "2021-09-22T14:37:59.632171Z"
    }
   },
   "outputs": [],
   "source": [
    "#terminal 에서 실행\n",
    "def f(x): print(x)\n",
    "spark.sparkContext.parallelize([1, 2, 3, 4, 5]).foreach(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74b77ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:39:02.939659Z",
     "start_time": "2021-09-22T14:39:02.907921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "upper2list=wordsRdd.map(lambda x: [i.upper() for i in x]).collect()\n",
    "print (type(upper2list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5957de89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:39:12.160015Z",
     "start_time": "2021-09-22T14:39:12.127047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2]\n"
     ]
    }
   ],
   "source": [
    "wordsLength = wordsRdd\\\n",
    "    .map(len)\\\n",
    "    .collect()\n",
    "print (wordsLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "484f4936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:40:05.475206Z",
     "start_time": "2021-09-22T14:40:05.007369Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.parallelize(upper2list).saveAsTextFile(\"../data/ds_spark_wiki_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fcfb011a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:40:21.011760Z",
     "start_time": "2021-09-22T14:40:20.859886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "-rw-r--r--  1 jinsungkim  staff   0 Sep 22 23:40 _SUCCESS\r\n",
      "-rw-r--r--  1 jinsungkim  staff  29 Sep 22 23:40 part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data/ds_spark_wiki_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c6fef18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:41:19.075294Z",
     "start_time": "2021-09-22T14:41:18.999146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['THIS', 'IS']\", \"['A', 'LINE']\"]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rdd=spark.sparkContext.textFile(\"../data/ds_spark_wiki_out\")\n",
    "_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02c9f1c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:42:19.012364Z",
     "start_time": "2021-09-22T14:42:18.837680Z"
    }
   },
   "outputs": [],
   "source": [
    "_rdd.map(lambda x: \"\".join(x)).coalesce(1).saveAsTextFile(\"../data/ds_spark_wiki_txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9e6c8c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:42:20.086423Z",
     "start_time": "2021-09-22T14:42:19.964273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THIS', 'IS']\r\n",
      "['A', 'LINE']\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../data/ds_spark_wiki_txt/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf945102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:42:46.994726Z",
     "start_time": "2021-09-22T14:42:46.962839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wikipedia',\n",
       " 'Apache Spark is an open source cluster computing framework.',\n",
       " '아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다.',\n",
       " 'Apache Spark Apache Spark Apache Spark Apache Spark',\n",
       " '아파치 스파크 아파치 스파크 아파치 스파크 아파치 스파크',\n",
       " \"Originally developed at the University of California, Berkeley's AMPLab,\",\n",
       " 'the Spark codebase was later donated to the Apache Software Foundation,',\n",
       " 'which has maintained it since.',\n",
       " 'Spark provides an interface for programming entire clusters with',\n",
       " 'implicit data parallelism and fault-tolerance.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "deed6fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:44:21.171107Z",
     "start_time": "2021-09-22T14:44:21.024584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wi: Wikipedia\n",
      "-----\n",
      "Ap: Apache Spark is an open source cluster computing framework.\n",
      "Ap: Apache Spark Apache Spark Apache Spark Apache Spark\n",
      "-----\n",
      "아파: 아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다.\n",
      "아파: 아파치 스파크 아파치 스파크 아파치 스파크 아파치 스파크\n",
      "-----\n",
      "Or: Originally developed at the University of California, Berkeley's AMPLab,\n",
      "-----\n",
      "th: the Spark codebase was later donated to the Apache Software Foundation,\n",
      "-----\n",
      "wh: which has maintained it since.\n",
      "-----\n",
      "Sp: Spark provides an interface for programming entire clusters with\n",
      "-----\n",
      "im: implicit data parallelism and fault-tolerance.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "#myRdd_group=myRdd2.flatMap(lambda x:x.split()).groupBy(lambda x:w[0:2])\n",
    "myRdd_group=myRdd2.groupBy(lambda x:x[0:2])\n",
    "\n",
    "for (k,v) in myRdd_group.collect():\n",
    "    for eachValue in v:\n",
    "        print (\"{}: {}\".format(k, eachValue))\n",
    "    print (\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3dea2fcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:44:47.335336Z",
     "start_time": "2021-09-22T14:44:47.331606Z"
    }
   },
   "outputs": [],
   "source": [
    "_testList=[(\"Seoul\",1),(\"Seoul\",1),(\"Seoul\",1),(\"Busan\",1),(\"Busan\",1),\n",
    "           (\"Seoul\",1),(\"Busan\",1),\n",
    "           (\"Seoul\",1),(\"Seoul\",1),(\"Busan\",1),(\"Busan\",1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f12e3a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:45:41.019950Z",
     "start_time": "2021-09-22T14:45:41.013181Z"
    }
   },
   "outputs": [],
   "source": [
    "_testRdd=spark.sparkContext.parallelize(_testList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53f1ca2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:45:50.151383Z",
     "start_time": "2021-09-22T14:45:50.057117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Seoul', <pyspark.resultiterable.ResultIterable at 0x7f96bdfc0670>),\n",
       " ('Busan', <pyspark.resultiterable.ResultIterable at 0x7f96be4fcdf0>)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupBy(lambda x:x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "decf7520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:46:09.543718Z",
     "start_time": "2021-09-22T14:46:09.463945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Seoul',\n",
       "  [('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1)]),\n",
       " ('Busan',\n",
       "  [('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1)])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupBy(lambda x:x[0]).mapValues(lambda x: list(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abe6a591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:47:06.119234Z",
     "start_time": "2021-09-22T14:47:06.034187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Seoul',\n",
       "  [('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1)]),\n",
       " ('Busan',\n",
       "  [('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1)])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupBy(lambda x:x[0]).mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bba29",
   "metadata": {},
   "source": [
    "## pair rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc0760cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:49:01.571107Z",
     "start_time": "2021-09-22T14:49:01.564155Z"
    }
   },
   "outputs": [],
   "source": [
    "_testList=[(\"key1\",1),(\"key1\",1),(\"key1\",1),(\"key2\",1),(\"key2\",1),\n",
    "           (\"key1\",1),(\"key2\",1),\n",
    "           (\"key1\",1),(\"key1\",1),(\"key2\",1),(\"key2\",1)]\n",
    "_testRdd=spark.sparkContext.parallelize(_testList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7e89528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:49:10.040107Z",
     "start_time": "2021-09-22T14:49:10.035405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79b92568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:49:40.825909Z",
     "start_time": "2021-09-22T14:49:40.821351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, jsl 2020.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2020\n",
    "name = 'jsl'\n",
    "f\"Hello, {name} {year}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e4021fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:49:50.845234Z",
     "start_time": "2021-09-22T14:49:50.808707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions 0 -> [('key1', 1), ('key1', 1), ('key1', 1), ('key2', 1), ('key2', 1), ('key1', 1), ('key2', 1), ('key1', 1), ('key1', 1), ('key2', 1), ('key2', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 파티션 개수 파악\n",
    "\n",
    "partitions = _testRdd.glom().collect()\n",
    "for num, partition in enumerate(partitions):\n",
    "    print(f'Partitions {num} -> {partition}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a083de8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:50:14.047792Z",
     "start_time": "2021-09-22T14:50:14.016025Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key1',\n",
       " 'key1',\n",
       " 'key1',\n",
       " 'key2',\n",
       " 'key2',\n",
       " 'key1',\n",
       " 'key2',\n",
       " 'key1',\n",
       " 'key1',\n",
       " 'key2',\n",
       " 'key2']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.keys().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495bcc25",
   "metadata": {},
   "source": [
    "## 두개 차이 알기 reduce, groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6340d138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:55:39.696534Z",
     "start_time": "2021-09-22T14:55:39.609729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key1', 6), ('key2', 5)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ecce71c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:55:50.716214Z",
     "start_time": "2021-09-22T14:55:50.646623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key1', <pyspark.resultiterable.ResultIterable at 0x7f96bdfc01f0>),\n",
       " ('key2', <pyspark.resultiterable.ResultIterable at 0x7f96beabd3d0>)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82272eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:56:25.048176Z",
     "start_time": "2021-09-22T14:56:24.976132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key1', [1, 1, 1, 1, 1, 1]), ('key2', [1, 1, 1, 1, 1])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupByKey().mapValues(list).collect() # list is a function, that is, list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71797e61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:56:35.653570Z",
     "start_time": "2021-09-22T14:56:35.623134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key1', 2),\n",
       " ('key1', 2),\n",
       " ('key1', 2),\n",
       " ('key2', 2),\n",
       " ('key2', 2),\n",
       " ('key1', 2),\n",
       " ('key2', 2),\n",
       " ('key1', 2),\n",
       " ('key1', 2),\n",
       " ('key2', 2),\n",
       " ('key2', 2)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.mapValues(lambda x:x+1).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14496936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:56:48.173312Z",
     "start_time": "2021-09-22T14:56:48.099413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wikipedia', <pyspark.resultiterable.ResultIterable at 0x7f96bdfc0610>),\n",
       " ('Apache', <pyspark.resultiterable.ResultIterable at 0x7f96bdfc00a0>),\n",
       " ('Spark', <pyspark.resultiterable.ResultIterable at 0x7f96bdfc0c40>)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\#단어 빈도세기\n",
    "    .groupByKey()\\\n",
    "    .take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd873c00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:58:03.462554Z",
     "start_time": "2021-09-22T14:58:03.384766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wikipedia', 1),\n",
       " ('Apache', 6),\n",
       " ('Spark', 7),\n",
       " ('is', 1),\n",
       " ('an', 2),\n",
       " ('open', 1),\n",
       " ('source', 1),\n",
       " ('cluster', 1),\n",
       " ('computing', 1),\n",
       " ('framework.', 1),\n",
       " ('아파치', 5),\n",
       " ('스파크는', 1),\n",
       " ('오픈', 1),\n",
       " ('소스', 1),\n",
       " ('클러스터', 1),\n",
       " ('컴퓨팅', 1),\n",
       " ('프레임워크이다.', 1),\n",
       " ('스파크', 4),\n",
       " ('Originally', 1),\n",
       " ('developed', 1)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어 빈도 세기\n",
    "\n",
    "myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .groupByKey()\\\n",
    "    .mapValues(sum)\\\n",
    "    .take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f95cc477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:59:05.330630Z",
     "start_time": "2021-09-22T14:59:05.253717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AMPLab,', 1),\n",
       " ('Apache', 6),\n",
       " (\"Berkeley's\", 1),\n",
       " ('California,', 1),\n",
       " ('Foundation,', 1),\n",
       " ('Originally', 1),\n",
       " ('Software', 1),\n",
       " ('Spark', 7),\n",
       " ('University', 1),\n",
       " ('Wikipedia', 1)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x): return len(x)\n",
    "myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .groupByKey()\\\n",
    "    .mapValues(f)\\\n",
    "    .sortByKey(True)\\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88e236ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:59:32.366198Z",
     "start_time": "2021-09-22T14:59:32.300351Z"
    }
   },
   "outputs": [],
   "source": [
    "wc=myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .groupByKey()\\\n",
    "    .mapValues(sum)\\\n",
    "    .sortByKey(True)\\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65e87946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T14:59:42.289806Z",
     "start_time": "2021-09-22T14:59:42.285758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어:AMPLab,\t\t빈도:1\n",
      "단어:Apache\t\t빈도:6\n",
      "단어:Berkeley's\t\t빈도:1\n",
      "단어:California,\t\t빈도:1\n",
      "단어:Foundation,\t\t빈도:1\n",
      "단어:Originally\t\t빈도:1\n",
      "단어:Software\t\t빈도:1\n",
      "단어:Spark\t\t빈도:7\n",
      "단어:University\t\t빈도:1\n",
      "단어:Wikipedia\t\t빈도:1\n"
     ]
    }
   ],
   "source": [
    "for e in wc:\n",
    "    k = e[0]\n",
    "    v = e[1]\n",
    "    print (f\"단어:{k}\\t\\t빈도:{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ba054f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T15:00:32.083019Z",
     "start_time": "2021-09-22T15:00:32.013087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wikipedia', 1),\n",
       " ('Apache', 6),\n",
       " ('Spark', 7),\n",
       " ('is', 1),\n",
       " ('an', 2),\n",
       " ('open', 1),\n",
       " ('source', 1),\n",
       " ('cluster', 1),\n",
       " ('computing', 1),\n",
       " ('framework.', 1)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .reduceByKey(lambda x,y:x+y)\\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8aeb7597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T15:01:18.705814Z",
     "start_time": "2021-09-22T15:01:18.670552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Wikipedia': 1,\n",
       "             'Apache': 6,\n",
       "             'Spark': 7,\n",
       "             'is': 1,\n",
       "             'an': 2,\n",
       "             'open': 1,\n",
       "             'source': 1,\n",
       "             'cluster': 1,\n",
       "             'computing': 1,\n",
       "             'framework.': 1,\n",
       "             '아파치': 5,\n",
       "             '스파크는': 1,\n",
       "             '오픈': 1,\n",
       "             '소스': 1,\n",
       "             '클러스터': 1,\n",
       "             '컴퓨팅': 1,\n",
       "             '프레임워크이다.': 1,\n",
       "             '스파크': 4,\n",
       "             'Originally': 1,\n",
       "             'developed': 1,\n",
       "             'at': 1,\n",
       "             'the': 3,\n",
       "             'University': 1,\n",
       "             'of': 1,\n",
       "             'California,': 1,\n",
       "             \"Berkeley's\": 1,\n",
       "             'AMPLab,': 1,\n",
       "             'codebase': 1,\n",
       "             'was': 1,\n",
       "             'later': 1,\n",
       "             'donated': 1,\n",
       "             'to': 1,\n",
       "             'Software': 1,\n",
       "             'Foundation,': 1,\n",
       "             'which': 1,\n",
       "             'has': 1,\n",
       "             'maintained': 1,\n",
       "             'it': 1,\n",
       "             'since.': 1,\n",
       "             'provides': 1,\n",
       "             'interface': 1,\n",
       "             'for': 1,\n",
       "             'programming': 1,\n",
       "             'entire': 1,\n",
       "             'clusters': 1,\n",
       "             'with': 1,\n",
       "             'implicit': 1,\n",
       "             'data': 1,\n",
       "             'parallelism': 1,\n",
       "             'and': 1,\n",
       "             'fault-tolerance.': 1})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .countByKey() # .items() to be added to get a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1dbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
